{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "6893_HW2PartI_LogisticRegression.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "6hKq-n7G62-2"
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5_jvhfhtFCj"
   },
   "source": [
    "1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_Yi3ww9VtSKs"
   },
   "source": [
    "#Read csv file to dataframe\n",
    "#=====your code here==========\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#===============================\n",
    "data.show(3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i9ZrT0OR79To"
   },
   "source": [
    "from functools import reduce"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u9vNg2LFtoJK"
   },
   "source": [
    "#change the column names of dataframe\n",
    "df = data.withColumnRenamed('_c0','age').withColumnRenamed('_c1','workclass').withColumnRenamed('_c2','fnlwgt')\\\n",
    ".withColumnRenamed('_c3', 'education').withColumnRenamed('_c4', 'education_num')\\\n",
    ".withColumnRenamed('_c5','marital_status').withColumnRenamed('_c6', 'occupation').withColumnRenamed('_c7', 'relationship')\\\n",
    ".withColumnRenamed('_c8', 'race').withColumnRenamed('_c9', 'sex').withColumnRenamed('_c10', 'capital_gain')\\\n",
    ".withColumnRenamed('_c11', 'capital_loss').withColumnRenamed('_c12','hours_per_week')\\\n",
    ".withColumnRenamed('_c13', 'native_country').withColumnRenamed('_c14', 'income')\n",
    "\n",
    "df.printSchema()\n",
    "df.show(2)\n",
    "\n",
    "dataset = df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeRTQAUE6VfO"
   },
   "source": [
    "2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3TKctNhO6bHG"
   },
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_83QyptU_nDE"
   },
   "source": [
    "#stages in our Pipeline\n",
    "stages = []\n",
    "categoricalColumns = [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native_country\"]"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CWCBHX35A4s1"
   },
   "source": [
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iNkhx2QVA-1b"
   },
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BB4TOB6MBCJ3"
   },
   "source": [
    "# Transform all features into a vector using VectorAssembler\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ab0WDG00Bqc0"
   },
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(dataset)\n",
    "preppedDataDF = pipelineModel.transform(dataset)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-x6nXJUiByOE"
   },
   "source": [
    "preppedDataDF.take(3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NPONX19OB2Tu"
   },
   "source": [
    "# Keep relevant columns\n",
    "cols = dataset.columns\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZYB1oCw4CJuc"
   },
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "#=====your code here==========\n",
    "\n",
    "\n",
    "\n",
    "#===============================\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STxwMITSBLEH"
   },
   "source": [
    "3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2mej0dQPC22x"
   },
   "source": [
    "# Fit model to prepped data\n",
    "\n",
    "#LogisticRegression model, maxIter=10\n",
    "#=====your code here==========\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#===============================\n",
    "\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7AwIbeIwbpsY"
   },
   "source": [
    "#Random Forest\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PHc1qAd6Skf1"
   },
   "source": [
    "#NaiveBayes\n",
    "#=====your code here==========\n",
    "\n",
    "\n",
    "\n",
    "#===============================\n",
    "\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = nbModel.transform(testData)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PBbr8btnbyV3"
   },
   "source": [
    "#Decision Tree\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4nccBiy_b8KT"
   },
   "source": [
    "#Gradient Boosting Trees\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O9sNFLH0b_LH"
   },
   "source": [
    "# Multi-layer Perceptron\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AG_EmZcfcCIU"
   },
   "source": [
    "# Linear Support Vector Machine\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IvJc9VXrcGFU"
   },
   "source": [
    "# One-vs-Rest\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WIIE8pEDSR9"
   },
   "source": [
    "4. Comparison and analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LpoclCFXD7tV"
   },
   "source": [
    "# Rank models according to Test set accuracy\n",
    "#=====your code here==========\n",
    "\n",
    "\n",
    "#==============================="
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL3j030aa7M8"
   },
   "source": [
    "*your analysis*"
   ]
  }
 ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6893_HW2PartII_LDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjlYUoo3nK-9"
      },
      "source": [
        "from pyspark import SparkConf, SparkContext,SQLContext  \n",
        "from pyspark.sql import SparkSession   \n",
        "from pyspark.ml.feature import Word2Vec,CountVectorizer  \n",
        "from pyspark.ml.clustering import LDA, LDAModel  \n",
        "from pyspark.sql.functions import col, udf  \n",
        "from pyspark.sql.types import IntegerType,ArrayType,StringType  \n",
        "import pylab as pl  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4jjf6wWnU3D"
      },
      "source": [
        "def to_word(termIndices):\n",
        "  words = []  \n",
        "  for termID in termIndices:\n",
        "    words.append(vocab_broadcast.value[termID])      \n",
        "  return words"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbEMpBH_nrPy"
      },
      "source": [
        "#Load your document dataframe here\n",
        "#================your code here==================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#==================================================\n",
        "spark_df.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M16Wh6YhoDoH"
      },
      "source": [
        "#CountVectorizer\n",
        "#================your code here==================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#=================================================="
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5pLaBZolAq"
      },
      "source": [
        "#train LDA model, cluster the documents into 10 topics \n",
        "#================your code here==================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#=================================================="
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovzUq8JPow3S"
      },
      "source": [
        "transformed = ldaModel.transform(cvResult).select(\"topicDistribution\")  \n",
        "#show the weight of every topic Distribution \n",
        "transformed.show(truncate=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz6D0Tllo5bs"
      },
      "source": [
        "#The higher ll is, the lower lp is, the better model is.\n",
        "ll = ldaModel.logLikelihood(cvResult)  \n",
        "lp = ldaModel.logPerplexity(cvResult)\n",
        "print(\"ll: \", ll)\n",
        "print(\"lp: \", lp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ_Ukzz4sS69"
      },
      "source": [
        "# Output topics. Each is a distribution over words (matching word count vectors)\n",
        "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())+ \" words):\")\n",
        "topics = ldaModel.topicsMatrix()\n",
        "print(topics)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}